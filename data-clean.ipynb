{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read clean dataset\n",
    "data = pd.read_pickle(\"data/MAD_BAR_all.pkl\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Turista\": {\"Promo\": {\"price\": 101.5, \"seats\": 248}, \"Promo +\": {\"price\": 107.95, \"seats\": 248}, \"Flexible\": {\"price\": 128.5, \"seats\": 248}}, \"Preferente\": {\"Mesa\": {\"price\": 346.4, \"seats\": 12}, \"Promo\": {\"price\": 99.6, \"seats\": 57}, \"Promo +\": {\"price\": 110.4, \"seats\": 57}, \"Flexible\": {\"price\": 216.5, \"seats\": 57}}, \"Turista Plus\": {\"Promo\": {\"price\": 95.6, \"seats\": 49}, \"Promo +\": {\"price\": 103.3, \"seats\": 49}, \"Flexible\": {\"price\": 154.2, \"seats\": 49}}}'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[301030, \"meta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate train_id\n",
    "data[\"train_id\"] = data[[\"origin\", \"destination\", \"departure\",\"arrival\"]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"weekday\"] = data[\"departure\"].apply(\n",
    "    lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").weekday()\n",
    ")\n",
    "data[\"depart_month\"] = data[\"departure\"].apply(\n",
    "    lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").month\n",
    ")\n",
    "data[\"depart_hour\"] = data[\"departure\"].apply(\n",
    "    lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").hour\n",
    ")\n",
    "# only jan, feb, march,\n",
    "data = data.loc[data[\"depart_month\"] < 4].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"depart_year\"] = data[\"departure\"].apply(\n",
    "    lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").year\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    458876\n",
       "Name: depart_year, dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"depart_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1514"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"train_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a price-seat adatok a meta változóban vannak,\n",
    "# ami egy mindig más struktúrájú dictionary,\n",
    "# elég trükkös volt kinyerni, arra írtam ezt a fgv-t\n",
    "\n",
    "\n",
    "def extract_meta(train):\n",
    "    prices_seats = pd.DataFrame()\n",
    "    for i in tqdm(range(train.shape[0])):\n",
    "        dic_in = json.loads(train.meta[i])\n",
    "        # extract values from tree dictionary\n",
    "        while type(list(dic_in.values())[0]) != float:\n",
    "            res = {key: list(value) for key, value in dic_in.items()}\n",
    "            dic_out = {}\n",
    "            for key in res.keys():\n",
    "                for value in res[key]:\n",
    "                    dic_out[key + \"_\" + value] = dic_in[key][value]\n",
    "            dic_in = dic_out\n",
    "\n",
    "        # check for seats, if no seat its the price\n",
    "        for key in list(dic_in.keys()):\n",
    "            if \"seats\" not in key:\n",
    "                if \"price\" not in key:\n",
    "                    dic_in[key + \"_price\"] = dic_in[key]\n",
    "                    dic_in.pop(key)\n",
    "\n",
    "        prices_seats = pd.concat(\n",
    "            [prices_seats, pd.DataFrame.from_dict(dic_in, orient=\"index\").T]\n",
    "        ).reset_index(drop=True)\n",
    "    return prices_seats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:37<00:00, 267.82it/s]\n",
      "100%|██████████| 10000/10000 [00:34<00:00, 287.98it/s]\n",
      "100%|██████████| 10000/10000 [00:36<00:00, 270.29it/s]\n",
      "100%|██████████| 10000/10000 [00:38<00:00, 257.02it/s]\n",
      "100%|██████████| 10000/10000 [00:44<00:00, 224.91it/s]\n",
      "100%|██████████| 10000/10000 [00:37<00:00, 267.27it/s]\n",
      "100%|██████████| 10000/10000 [00:33<00:00, 302.20it/s]\n",
      "100%|██████████| 10000/10000 [00:35<00:00, 278.03it/s]\n",
      "100%|██████████| 10000/10000 [00:33<00:00, 300.40it/s]\n",
      "100%|██████████| 10000/10000 [00:33<00:00, 301.06it/s]\n",
      "100%|██████████| 10000/10000 [00:35<00:00, 282.36it/s]\n",
      "100%|██████████| 10000/10000 [00:35<00:00, 282.92it/s]\n",
      "100%|██████████| 10000/10000 [00:37<00:00, 268.64it/s]\n",
      "100%|██████████| 10000/10000 [00:43<00:00, 229.79it/s]\n",
      "100%|██████████| 10000/10000 [00:43<00:00, 229.61it/s]\n",
      "100%|██████████| 10000/10000 [00:43<00:00, 230.33it/s]\n",
      "100%|██████████| 10000/10000 [00:42<00:00, 233.99it/s]\n",
      "100%|██████████| 10000/10000 [00:45<00:00, 222.05it/s]\n",
      "100%|██████████| 10000/10000 [00:43<00:00, 231.12it/s]\n",
      "100%|██████████| 10000/10000 [00:43<00:00, 228.45it/s]\n",
      "100%|██████████| 10000/10000 [00:46<00:00, 215.88it/s]\n",
      "100%|██████████| 10000/10000 [00:43<00:00, 228.16it/s]\n",
      "100%|██████████| 10000/10000 [12:38<00:00, 13.18it/s]  \n",
      "100%|██████████| 10000/10000 [21:48<00:00,  7.64it/s]  \n",
      "100%|██████████| 10000/10000 [33:25<00:00,  4.99it/s]  \n",
      "100%|██████████| 10000/10000 [00:59<00:00, 168.94it/s]\n",
      "100%|██████████| 10000/10000 [35:31<00:00,  4.69it/s] \n",
      "100%|██████████| 10000/10000 [00:41<00:00, 238.71it/s]\n",
      "100%|██████████| 10000/10000 [03:57<00:00, 42.05it/s] \n",
      "100%|██████████| 10000/10000 [05:06<00:00, 32.64it/s] \n",
      "100%|██████████| 10000/10000 [10:49<00:00, 15.40it/s] \n",
      "100%|██████████| 10000/10000 [01:05<00:00, 152.04it/s]\n",
      "100%|██████████| 10000/10000 [41:42<00:00,  4.00it/s]  \n",
      "100%|██████████| 10000/10000 [00:44<00:00, 226.04it/s]\n",
      "100%|██████████| 10000/10000 [15:10<00:00, 10.99it/s]  \n",
      "100%|██████████| 10000/10000 [36:50<00:00,  4.52it/s]  \n",
      "100%|██████████| 10000/10000 [00:51<00:00, 195.68it/s]\n",
      "100%|██████████| 10000/10000 [00:46<00:00, 216.71it/s]\n",
      "100%|██████████| 10000/10000 [00:44<00:00, 226.41it/s]\n",
      "100%|██████████| 10000/10000 [00:46<00:00, 214.69it/s]\n",
      "100%|██████████| 10000/10000 [00:52<00:00, 191.75it/s]\n",
      "100%|██████████| 10000/10000 [00:50<00:00, 198.54it/s]\n",
      "100%|██████████| 10000/10000 [00:43<00:00, 228.63it/s]\n",
      "100%|██████████| 10000/10000 [00:53<00:00, 185.92it/s]\n",
      "100%|██████████| 10000/10000 [00:39<00:00, 253.89it/s]\n"
     ]
    }
   ],
   "source": [
    "chunks = {\n",
    "    i: pd.concat(\n",
    "        [\n",
    "            data.loc[i * 10000 : i * 10000 + 9999, :].reset_index(drop=True),\n",
    "            extract_meta(\n",
    "                data.loc[i * 10000 : i * 10000 + 9999, :].reset_index(drop=True)\n",
    "            ),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    for i in range(45)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(list(chunks.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8876/8876 [00:32<00:00, 274.96it/s]\n"
     ]
    }
   ],
   "source": [
    "last_chunk = pd.concat(\n",
    "    [\n",
    "        data.loc[450000:, :].reset_index(drop=True),\n",
    "        extract_meta(data.loc[450000:, :].reset_index(drop=True)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,last_chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"id\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\n",
    "    columns=[\n",
    "        \"Preferente_YOVOY_price\",\n",
    "        \"Preferente_YOVOY_seats\",\n",
    "        \"Turista Plus_YOVOY_price\",\n",
    "        \"Turista Plus_YOVOY_seats\",\n",
    "        \"Turista_YOVOY VERANO_price\",\n",
    "        \"Turista_YOVOY VERANO_seats\",\n",
    "        \"Preferente_YOVOY VERANO_price\",\n",
    "        \"Preferente_YOVOY VERANO_seats\",\n",
    "        \"Turista Plus_YOVOY VERANO_price\",\n",
    "        \"Turista Plus_YOVOY VERANO_seats\",\n",
    "        \"Preferente_Mesa_seats\",\n",
    "        \"Turista_Mesa_seats\",\n",
    "        \"Turista Plus_Mesa_seats\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"days_till_dep\"] = [\n",
    "    (\n",
    "        datetime.datetime.strptime(df.loc[i, \"departure\"][0:19], \"%Y-%m-%d %H:%M:%S\")\n",
    "        - datetime.datetime.strptime(\n",
    "            df.loc[i, \"insert_date\"][0:19], \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "    ).days\n",
    "    for i in range(df.shape[0])\n",
    "]\n",
    "\n",
    "df[\"timedelta_till_dep\"] = [\n",
    "    (\n",
    "        datetime.datetime.strptime(df.loc[i, \"departure\"][0:19], \"%Y-%m-%d %H:%M:%S\")\n",
    "        - datetime.datetime.strptime(\n",
    "            df.loc[i, \"insert_date\"][0:19], \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "    )\n",
    "    for i in range(df.shape[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"data/MAD_BAR_trains_v2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
