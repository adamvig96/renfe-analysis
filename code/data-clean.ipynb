{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read clean dataset\n",
    "filename = \"/Users/vigadam/Documents/github/renfe-analysis/data/1_routes/MAD_SEV_all.pkl\"\n",
    "\n",
    "data = pd.read_pickle(filename).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Turista\": {\"Promo\": 47.8, \"Promo +\": 51.65, \"Flexible\": 77.1}, \"Preferente\": {\"Promo\": 80.55, \"Promo +\": 87.05, \"Flexible\": 129.9}}'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[30030, \"meta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate train_id\n",
    "data[\"train_id\"] = data[[\"origin\", \"destination\", \"departure\",\"arrival\"]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"weekday\"] = data[\"departure\"].apply(\n",
    "    lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").weekday()\n",
    ")\n",
    "data[\"depart_month\"] = data[\"departure\"].apply(\n",
    "    lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").month\n",
    ")\n",
    "data[\"depart_hour\"] = data[\"departure\"].apply(\n",
    "    lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").hour\n",
    ")\n",
    "# only jan, feb, march,\n",
    "data = data.loc[data[\"depart_month\"] < 4].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"depart_year\"] = data[\"departure\"].apply(\n",
    "    lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").year\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    284175\n",
       "Name: depart_year, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"depart_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "973"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"train_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a price-seat adatok a meta változóban vannak,\n",
    "# ami egy mindig más struktúrájú dictionary,\n",
    "# elég trükkös volt kinyerni, arra írtam ezt a fgv-t\n",
    "\n",
    "\n",
    "def extract_meta(train):\n",
    "    prices_seats = pd.DataFrame()\n",
    "    for i in tqdm(range(train.shape[0])):\n",
    "        dic_in = json.loads(train.meta[i])\n",
    "        # extract values from tree dictionary\n",
    "        while type(list(dic_in.values())[0]) != float:\n",
    "            res = {key: list(value) for key, value in dic_in.items()}\n",
    "            dic_out = {}\n",
    "            for key in res.keys():\n",
    "                for value in res[key]:\n",
    "                    dic_out[key + \"_\" + value] = dic_in[key][value]\n",
    "            dic_in = dic_out\n",
    "\n",
    "        # check for seats, if no seat its the price\n",
    "        for key in list(dic_in.keys()):\n",
    "            if \"seats\" not in key:\n",
    "                if \"price\" not in key:\n",
    "                    dic_in[key + \"_price\"] = dic_in[key]\n",
    "                    dic_in.pop(key)\n",
    "\n",
    "        prices_seats = pd.concat(\n",
    "            [prices_seats, pd.DataFrame.from_dict(dic_in, orient=\"index\").T]\n",
    "        ).reset_index(drop=True)\n",
    "    return prices_seats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.shape[0]//10000)*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:32<00:00, 305.31it/s]\n",
      "100%|██████████| 10000/10000 [00:29<00:00, 334.61it/s]\n",
      "100%|██████████| 10000/10000 [00:31<00:00, 316.86it/s]\n",
      "100%|██████████| 10000/10000 [00:36<00:00, 272.51it/s]\n",
      "100%|██████████| 10000/10000 [00:39<00:00, 254.54it/s]\n",
      "100%|██████████| 10000/10000 [00:31<00:00, 315.66it/s]\n",
      "100%|██████████| 10000/10000 [01:09<00:00, 144.80it/s]\n",
      "100%|██████████| 10000/10000 [00:31<00:00, 313.00it/s]\n",
      "100%|██████████| 10000/10000 [00:55<00:00, 179.16it/s]\n",
      "100%|██████████| 10000/10000 [00:44<00:00, 226.47it/s]\n",
      "100%|██████████| 10000/10000 [00:39<00:00, 251.42it/s]\n",
      "100%|██████████| 10000/10000 [00:42<00:00, 235.80it/s]\n",
      "100%|██████████| 10000/10000 [00:45<00:00, 219.15it/s]\n",
      "100%|██████████| 10000/10000 [00:42<00:00, 232.76it/s]\n",
      "100%|██████████| 10000/10000 [00:44<00:00, 224.70it/s]\n",
      "100%|██████████| 10000/10000 [00:49<00:00, 203.70it/s]\n",
      "100%|██████████| 10000/10000 [00:40<00:00, 245.67it/s]\n",
      "100%|██████████| 10000/10000 [00:48<00:00, 208.27it/s]\n",
      "100%|██████████| 10000/10000 [00:54<00:00, 182.39it/s]\n",
      "100%|██████████| 10000/10000 [00:42<00:00, 237.03it/s]\n",
      "100%|██████████| 10000/10000 [00:44<00:00, 227.17it/s]\n",
      "100%|██████████| 10000/10000 [00:44<00:00, 224.62it/s]\n",
      "100%|██████████| 10000/10000 [00:42<00:00, 236.63it/s]\n",
      "100%|██████████| 10000/10000 [00:41<00:00, 238.63it/s]\n",
      "100%|██████████| 10000/10000 [00:42<00:00, 233.85it/s]\n",
      "100%|██████████| 10000/10000 [00:40<00:00, 248.54it/s]\n",
      "100%|██████████| 10000/10000 [00:46<00:00, 217.17it/s]\n",
      "100%|██████████| 10000/10000 [00:38<00:00, 261.76it/s]\n"
     ]
    }
   ],
   "source": [
    "chunks = {\n",
    "    i: pd.concat(\n",
    "        [\n",
    "            data.loc[i * 10000 : i * 10000 + 9999, :].reset_index(drop=True),\n",
    "            extract_meta(\n",
    "                data.loc[i * 10000 : i * 10000 + 9999, :].reset_index(drop=True)\n",
    "            ),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    for i in range(data.shape[0]//10000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(list(chunks.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4175/4175 [00:15<00:00, 277.25it/s]\n"
     ]
    }
   ],
   "source": [
    "last_chunk = pd.concat(\n",
    "    [\n",
    "        data.loc[(data.shape[0]//10000)*10000:, :].reset_index(drop=True),\n",
    "        extract_meta(data.loc[(data.shape[0]//10000)*10000:, :].reset_index(drop=True)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,last_chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"id\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'company', 'origin', 'destination', 'departure', 'arrival',\n",
       "       'duration', 'vehicle_type', 'vehicle_class', 'price', 'fare', 'seats',\n",
       "       'meta', 'insert_date', 'train_id', 'weekday', 'depart_month',\n",
       "       'depart_hour', 'depart_year', 'Turista_Promo_price',\n",
       "       'Turista_Promo +_price', 'Turista_Flexible_price',\n",
       "       'Preferente_Promo_price', 'Preferente_Promo +_price',\n",
       "       'Preferente_Flexible_price', 'Turista_Mesa_price',\n",
       "       'Preferente_Mesa_price', 'Turista Plus_Flexible_price',\n",
       "       'Turista_Promo_seats', 'Turista_Promo +_seats',\n",
       "       'Turista_Flexible_seats', 'Preferente_Promo_seats',\n",
       "       'Preferente_Promo +_seats', 'Preferente_Flexible_seats',\n",
       "       'Preferente_Mesa_seats', 'Turista_Mesa_seats',\n",
       "       'Turista Plus_Flexible_seats', 'Turista Plus_Promo_price',\n",
       "       'Turista Plus_Promo_seats', 'Turista Plus_Promo +_price',\n",
       "       'Turista Plus_Promo +_seats', 'Preferente_YOVOY VERANO_price',\n",
       "       'Preferente_YOVOY VERANO_seats'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"days_till_dep\"] = [\n",
    "    (\n",
    "        datetime.datetime.strptime(df.loc[i, \"departure\"][0:19], \"%Y-%m-%d %H:%M:%S\")\n",
    "        - datetime.datetime.strptime(\n",
    "            df.loc[i, \"insert_date\"][0:19], \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "    ).days\n",
    "    for i in range(df.shape[0])\n",
    "]\n",
    "\n",
    "df[\"timedelta_till_dep\"] = [\n",
    "    (\n",
    "        datetime.datetime.strptime(df.loc[i, \"departure\"][0:19], \"%Y-%m-%d %H:%M:%S\")\n",
    "        - datetime.datetime.strptime(\n",
    "            df.loc[i, \"insert_date\"][0:19], \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "    )\n",
    "    for i in range(df.shape[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"/Users/vigadam/Documents/github/renfe-analysis/data/2_routes_excluded/MAD_SEV_trains.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
